{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from cube import Cube\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from copy import deepcopy\n",
    "import matplotlib.pyplot as plt\n",
    "from value_policy_net import ValuePolicyNet\n",
    "from resnet_model import ResnetModel\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 15\n",
    "l = 100\n",
    "M = 10\n",
    "\n",
    "lr = 1e-3\n",
    "batch_len = 32\n",
    "reward_type = 'deepcube' # what reward type to use, makes a difference only if value_only = False (DeepCube / MCTS). Values are 'deepcube' or 'dqn'.\n",
    "network_type = 'resnet' # what network type to use, makes a difference only if value_only = True (DeepCubeA / A*). Values are 'normal' or 'resnet'.\n",
    "value_only = True # value_only False trains the model for DeepCube (mcts), while True trains the model for DeepCubeA (A*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "action_encode = {\n",
    "    'F': 0,\n",
    "    'F\\'': 1,\n",
    "    'B': 2,\n",
    "    'B\\'': 3,\n",
    "    'L': 4,\n",
    "    'L\\'': 5,\n",
    "    'R': 6,\n",
    "    'R\\'': 7,\n",
    "    'U': 8,\n",
    "    'U\\'': 9,\n",
    "    'D': 10,\n",
    "    'D\\'': 11,\n",
    "}\n",
    "action_decode = {encoding: action for action,\n",
    "                 encoding in action_encode.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vp_net = ValuePolicyNet(value_only = value_only).to(device) if network_type == 'normal' else ResnetModel(20, 24, 5000, 1000, 4, 1, True).to(device)\n",
    "optim = torch.optim.RMSprop(vp_net.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scrambled_cubes(k, l):\n",
    "    states = []\n",
    "    for _ in range(l):\n",
    "        cube = Cube()\n",
    "        scramble_str = cube.get_scramble(k)\n",
    "        for rot_num, rot_code in enumerate(scramble_str.split(' ')):\n",
    "            cube.rotate_code(rot_code)\n",
    "            states.append(\n",
    "                (np.copy(cube.facelets), np.copy(cube.tracked), rot_num + 1))\n",
    "\n",
    "    return states\n",
    "\n",
    "\n",
    "def batchify(X, Y, W, batch_size):\n",
    "    x_batch = []\n",
    "    y_v_batch = []\n",
    "    y_p_batch = []\n",
    "    w_batch = []\n",
    "    for x, (y_v, y_p), w in zip(X, Y, W):\n",
    "        x_batch.append(x)\n",
    "        y_v_batch.append(y_v)\n",
    "        y_p_batch.append(y_p)\n",
    "        w_batch.append(w)\n",
    "        if len(x_batch) >= batch_size:\n",
    "            if value_only:\n",
    "                yield torch.Tensor(np.array(x_batch)).to(device), torch.Tensor(y_v_batch).to(device), None, torch.Tensor(w_batch).to(device)\n",
    "            else:\n",
    "                yield torch.Tensor(np.array(x_batch)).to(device), torch.Tensor(y_v_batch).to(device), torch.Tensor(y_p_batch).to(device), torch.Tensor(w_batch).to(device)\n",
    "            x_batch.clear()\n",
    "            y_v_batch.clear()\n",
    "            y_p_batch.clear()\n",
    "            w_batch.clear()\n",
    "    if len(x_batch) > 0:\n",
    "        if value_only:\n",
    "            yield torch.Tensor(np.array(x_batch)).to(device), torch.Tensor(y_v_batch).to(device), None, torch.Tensor(w_batch).to(device)\n",
    "        else:\n",
    "            yield torch.Tensor(np.array(x_batch)).to(device), torch.Tensor(y_v_batch).to(device), torch.Tensor(y_p_batch).to(device), torch.Tensor(w_batch).to(device)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0: loss = 2.5405327137163343\n",
      "Iteration 1: loss = 0.058827365926922635\n",
      "Iteration 2: loss = 0.13787022583741457\n",
      "Iteration 3: loss = 0.29903126500071364\n",
      "Iteration 4: loss = 0.45730155960042423\n",
      "Iteration 5: loss = 0.4954980884460693\n",
      "Iteration 6: loss = 0.7834279382641011\n",
      "Iteration 7: loss = 0.5885464679053489\n",
      "Iteration 8: loss = 0.48697023672309325\n",
      "Iteration 9: loss = 0.6495521133567425\n"
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "for it in range(M):\n",
    "    cube = Cube()\n",
    "    scrambled_cubes = get_scrambled_cubes(k, l)\n",
    "    F = [f for f, _, _ in scrambled_cubes]\n",
    "    T = [t for _, t, _ in scrambled_cubes]\n",
    "    W = [1 / n for _, _, n in scrambled_cubes]\n",
    "    X = [Cube.encode_state(t, cube.edges_corners) for t in T]\n",
    "    Y = []\n",
    "\n",
    "    vp_net.eval()\n",
    "    for f, t in zip(F, T):\n",
    "        v_x = []\n",
    "        r_x = []\n",
    "        solved = []\n",
    "        for a in range(12):\n",
    "            cube.facelets = np.copy(f)\n",
    "            cube.tracked = np.copy(t)\n",
    "            r_x_a = cube.rotate_code_get_reward(action_decode[a], reward_type)\n",
    "            with torch.no_grad():\n",
    "                net_out = vp_net(torch.Tensor(Cube.encode_state(cube.tracked, cube.edges_corners))[None, :].to(device))\n",
    "                # Even in the case of both value and policy, we only care about the value of the next state\n",
    "                v_x_a = net_out[0] if value_only else net_out[0][0]\n",
    "            solved.append(cube.is_solved())\n",
    "\n",
    "            v_x.append(v_x_a)\n",
    "            r_x.append(r_x_a)\n",
    "\n",
    "        v_x = torch.Tensor(v_x)\n",
    "        if not value_only: # For value and policy we set v_next to the reward if solved\n",
    "            r_x = torch.Tensor(r_x)\n",
    "\n",
    "            v_next = r_x + v_x\n",
    "            for a in range(12):\n",
    "                if solved[a]:\n",
    "                    v_next[a] = r_x[a]\n",
    "        else: # For value only, we don't care about rewards, as value is actually the approximated number of steps to solve\n",
    "            v_next = 1 + v_x\n",
    "            \n",
    "            for a in range(12):\n",
    "                if solved[a]:\n",
    "                    v_next[a] = 1 # TODO: makes more sense to be 1 here but what if it's actually 0? Maybe skim the paper again to check\n",
    "                \n",
    "        if not value_only: # For value and policy we get the max of the next values\n",
    "            y_v = torch.max(v_next)\n",
    "            y_p = torch.argmax(v_next)\n",
    "            Y.append((y_v, y_p))\n",
    "        else: # For value only we get the min of the next values\n",
    "            y_v = torch.min(v_next)\n",
    "            Y.append((y_v, None))\n",
    "    vp_net.train()\n",
    "\n",
    "    shuffle_indices = np.arange(len(X))\n",
    "    np.random.shuffle(shuffle_indices)\n",
    "    X = [X[i] for i in shuffle_indices]\n",
    "    Y = [Y[i] for i in shuffle_indices]\n",
    "    W = [W[i] for i in shuffle_indices]\n",
    "    \n",
    "    it_losses = []\n",
    "    for x_batch, y_v_batch, y_p_batch, w_batch in batchify(X, Y, W, batch_len):\n",
    "        optim.zero_grad()\n",
    "        if not value_only: # For value and policy we use both the loss of value and policy\n",
    "            y_v_pred, y_p_pred = vp_net(x_batch)\n",
    "            v_loss = torch.mean(w_batch * (y_v_batch - y_v_pred) ** 2)\n",
    "            p_loss = torch.mean(\n",
    "                w_batch * torch.nn.CrossEntropyLoss(reduction='none')(y_p_pred, y_p_batch.long()))\n",
    "            loss = v_loss + p_loss\n",
    "        else: # For value only we use only the loss of value\n",
    "            y_v_pred = vp_net(x_batch)\n",
    "            v_loss = torch.mean(w_batch * (y_v_batch - y_v_pred) ** 2)\n",
    "            loss = v_loss\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "\n",
    "        it_losses.append(loss.item())\n",
    "    it_loss = np.mean(it_losses)\n",
    "    losses.append(it_loss)\n",
    "\n",
    "    print(f'Iteration {it}: loss = {it_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(losses)\n",
    "plt.title('Average loss per iteration')\n",
    "ax = plt.gca()\n",
    "ax.set_ylim([0, 10])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(vp_net.state_dict(), 'vp_net.pt' if not value_only else f'v_net_{network_type}.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
