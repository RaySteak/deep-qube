{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from value_policy_net import ValuePolicyNet\n",
    "import matplotlib.pyplot as plt\n",
    "from copy import deepcopy\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from cube import Cube\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 5\n",
    "l = 1000\n",
    "M = 100\n",
    "\n",
    "lr = 1e-2\n",
    "batch_len = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "action_encode = {\n",
    "    'F': 0,\n",
    "    'F\\'': 1,\n",
    "    'B': 2,\n",
    "    'B\\'': 3,\n",
    "    'L': 4,\n",
    "    'L\\'': 5,\n",
    "    'R': 6,\n",
    "    'R\\'': 7,\n",
    "    'U': 8,\n",
    "    'U\\'': 9,\n",
    "    'D': 10,\n",
    "    'D\\'': 11,\n",
    "}\n",
    "action_decode = {encoding: action for action,\n",
    "                 encoding in action_encode.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vp_net = ValuePolicyNet().to(device)\n",
    "optim = torch.optim.RMSprop(vp_net.parameters(), lr=lr)\n",
    "criterion = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_state(tracked, edges, corners):\n",
    "    encoded = np.zeros((20, 24))\n",
    "    for f in range(6):\n",
    "        for i in range(3):\n",
    "            for j in range(3):\n",
    "                is_edge = (i == 1) or (j == 1)\n",
    "                if tracked[f, i, j] != -1:\n",
    "                    pos_value = edges[f, i, j] if is_edge else corners[f, i, j]\n",
    "                    encoded[tracked[f, i, j], pos_value] = 1\n",
    "\n",
    "    return encoded\n",
    "\n",
    "\n",
    "def get_scrambled_cubes(k, l):\n",
    "    states = []\n",
    "    for _ in range(l):\n",
    "        cube = Cube()\n",
    "        scramble_str = cube.get_scramble(k)\n",
    "        for rot_num, rot_code in enumerate(scramble_str.split(' ')):\n",
    "            cube.rotate_code(rot_code)\n",
    "            states.append(\n",
    "                (np.copy(cube.facelets), np.copy(cube.tracked), rot_num + 1))\n",
    "\n",
    "    return states\n",
    "\n",
    "\n",
    "def batchify(X, Y, W, batch_size):\n",
    "    x_batch = []\n",
    "    y_v_batch = []\n",
    "    y_p_batch = []\n",
    "    w_batch = []\n",
    "    for x, (y_v, y_p), w in zip(X, Y, W):\n",
    "        x_batch.append(x)\n",
    "        y_v_batch.append(y_v)\n",
    "        y_p_batch.append(y_p)\n",
    "        w_batch.append(w)\n",
    "        if len(x_batch) >= batch_size:\n",
    "            yield torch.Tensor(np.array(x_batch)).to(device), torch.Tensor(y_v_batch).to(device), torch.Tensor(y_p_batch).to(device), torch.Tensor(w_batch).to(device)\n",
    "            x_batch.clear()\n",
    "            y_v_batch.clear()\n",
    "            y_p_batch.clear()\n",
    "            w_batch.clear()\n",
    "    if len(x_batch) > 0:\n",
    "        yield torch.Tensor(np.array(x_batch)).to(device), torch.Tensor(y_v_batch).to(device), torch.Tensor(y_p_batch).to(device), torch.Tensor(w_batch).to(device)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0: loss = 7196550916.8323145\n",
      "Iteration 1: loss = 1265095.7908539013\n",
      "Iteration 2: loss = 432420.7629627787\n",
      "Iteration 3: loss = 215455.61726214172\n",
      "Iteration 4: loss = 109049.25375074641\n",
      "Iteration 5: loss = 27603.98858292695\n",
      "Iteration 6: loss = 7371.054787022293\n",
      "Iteration 7: loss = 5914.810246753085\n",
      "Iteration 8: loss = 3383.616701551304\n",
      "Iteration 9: loss = 4451.570175268088\n",
      "Iteration 10: loss = 4702.550200444119\n",
      "Iteration 11: loss = 1192.3695698148886\n",
      "Iteration 12: loss = 1446.7953809021385\n",
      "Iteration 13: loss = 1127.6952753735195\n",
      "Iteration 14: loss = 674718707.6322\n",
      "Iteration 15: loss = 2527698.043554607\n",
      "Iteration 16: loss = 18366.015712276385\n",
      "Iteration 17: loss = 6264.429064878233\n",
      "Iteration 18: loss = 87.61137619747478\n",
      "Iteration 19: loss = 25.061285884517012\n",
      "Iteration 20: loss = 26.43070491104369\n",
      "Iteration 21: loss = 25.987695915304172\n",
      "Iteration 22: loss = 2.958870300157055\n",
      "Iteration 23: loss = 1.0836115809287994\n",
      "Iteration 24: loss = 1.4354364149936825\n",
      "Iteration 25: loss = 3.0542936270626044\n",
      "Iteration 26: loss = 0.2175700439858524\n",
      "Iteration 27: loss = 0.20556039795118497\n",
      "Iteration 28: loss = 4.774494930459221\n",
      "Iteration 29: loss = 1.3832062926428144\n",
      "Iteration 30: loss = 0.4624307534426071\n",
      "Iteration 31: loss = 2.621758772049894\n",
      "Iteration 32: loss = 271.2795402407646\n",
      "Iteration 33: loss = 6.331389938000661\n",
      "Iteration 34: loss = 27.18662336905291\n",
      "Iteration 35: loss = 3.990844160128551\n",
      "Iteration 36: loss = 3.5928148069199484\n",
      "Iteration 37: loss = 4.778396904088889\n",
      "Iteration 38: loss = 865736.9934460821\n",
      "Iteration 39: loss = 0.28039659983270865\n",
      "Iteration 40: loss = 0.33532512415542304\n",
      "Iteration 41: loss = 7.273915396098874\n",
      "Iteration 42: loss = 0.20923649097947378\n",
      "Iteration 43: loss = 0.25876337847668607\n",
      "Iteration 44: loss = 0.18567186710340652\n",
      "Iteration 45: loss = 0.23657530217733502\n",
      "Iteration 46: loss = 1.8305352835547644\n",
      "Iteration 47: loss = 7.274429369124637\n",
      "Iteration 48: loss = 15.636419024199817\n",
      "Iteration 49: loss = 4.826139603071152\n",
      "Iteration 50: loss = 4.754491874366809\n",
      "Iteration 51: loss = 10.174562672141251\n",
      "Iteration 52: loss = 10.068993115880687\n",
      "Iteration 53: loss = 7.427905173058722\n",
      "Iteration 54: loss = 14.682300464362855\n",
      "Iteration 55: loss = 11.207628836677333\n",
      "Iteration 56: loss = 21.354421424258287\n",
      "Iteration 57: loss = 11.690144541916574\n",
      "Iteration 58: loss = 63.98822002957581\n",
      "Iteration 59: loss = 14.225376432868325\n",
      "Iteration 60: loss = 11.064527684715904\n",
      "Iteration 61: loss = 15.53002049057347\n",
      "Iteration 62: loss = 8.640746709647452\n",
      "Iteration 63: loss = 10.60663581805624\n",
      "Iteration 64: loss = 12.746761938568893\n",
      "Iteration 65: loss = 19.42112689413083\n",
      "Iteration 66: loss = 10.24946365386817\n",
      "Iteration 67: loss = 9.005965668684357\n",
      "Iteration 68: loss = 10.838431648388031\n",
      "Iteration 69: loss = 7.473094729101582\n",
      "Iteration 70: loss = 8.951905896804135\n",
      "Iteration 71: loss = 17.92771451184704\n",
      "Iteration 72: loss = 11.790132220383663\n",
      "Iteration 73: loss = 7.658268806281363\n",
      "Iteration 74: loss = 8.596256289512489\n",
      "Iteration 75: loss = 7.946957117433001\n",
      "Iteration 76: loss = 7.011420524044401\n",
      "Iteration 77: loss = 9.536926776740202\n",
      "Iteration 78: loss = 466.19818022752264\n",
      "Iteration 79: loss = 4.871856033422385\n",
      "Iteration 80: loss = 7.84555347671934\n",
      "Iteration 81: loss = 7.375734336816581\n",
      "Iteration 82: loss = 13.5649589247005\n",
      "Iteration 83: loss = 20.823537650381684\n",
      "Iteration 84: loss = 17.399661610080937\n",
      "Iteration 85: loss = 11.852161084011103\n",
      "Iteration 86: loss = 16.86719379835068\n",
      "Iteration 87: loss = 21.488975433786962\n",
      "Iteration 88: loss = 15.52374895059379\n",
      "Iteration 89: loss = 13.199665051357002\n",
      "Iteration 90: loss = 13.779142267385106\n",
      "Iteration 91: loss = 8.151170633401081\n",
      "Iteration 92: loss = 8.871644817340146\n",
      "Iteration 93: loss = 7.947023440318502\n",
      "Iteration 94: loss = 6.608351062817179\n",
      "Iteration 95: loss = 8.915065599854584\n",
      "Iteration 96: loss = 5.336513559339912\n",
      "Iteration 97: loss = 4.947246103529718\n",
      "Iteration 98: loss = 9.866127771936405\n",
      "Iteration 99: loss = 12.746311055626839\n"
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "for it in range(M):\n",
    "    cube = Cube()\n",
    "    scrambled_cubes = get_scrambled_cubes(k, l)\n",
    "    S = [f for f, _, _ in scrambled_cubes]\n",
    "    W = [1 / n for _, _, n in scrambled_cubes]\n",
    "    X = [encode_state(t, cube.edges, cube.corners)\n",
    "         for _, t, _ in scrambled_cubes]\n",
    "    Y = []\n",
    "\n",
    "    for s, x in zip(S, X):\n",
    "        v_x = []\n",
    "        p_x = []\n",
    "        r_x = []\n",
    "        solved = []\n",
    "        for a in range(12):\n",
    "            with torch.no_grad():\n",
    "                v_x_a, p_x_a = vp_net(torch.Tensor(x)[None, :].to(device))\n",
    "                v_x_a = v_x_a[0]\n",
    "                p_x_a = p_x_a[0]\n",
    "            cube.facelets = np.copy(s)\n",
    "            r_x_a = cube.rotate_code_get_reward(action_decode[a], 'deepcube')\n",
    "            solved.append(cube.is_solved())\n",
    "\n",
    "            v_x.append(v_x_a)\n",
    "            p_x.append(p_x_a)\n",
    "            r_x.append(r_x_a)\n",
    "\n",
    "        v_x = torch.Tensor(v_x)\n",
    "        p_x = torch.stack(p_x)\n",
    "        r_x = torch.Tensor(r_x)\n",
    "\n",
    "        v_next = r_x + v_x\n",
    "        for a in range(12):\n",
    "            if solved[a]:\n",
    "                v_next[a] = r_x[a]\n",
    "\n",
    "        y_v = torch.max(v_next)\n",
    "        y_p = torch.argmax(v_next)\n",
    "        Y.append((y_v, y_p))\n",
    "\n",
    "    # TODO: maybe shuffle samples\n",
    "    it_losses = []\n",
    "    for x_batch, y_v_batch, y_p_batch, w_batch in batchify(X, Y, W, batch_len):\n",
    "        optim.zero_grad()\n",
    "        y_v_pred, y_p_pred = vp_net(x_batch)\n",
    "        v_loss = torch.mean(w_batch * (y_v_batch - y_v_pred) ** 2)\n",
    "        p_loss = torch.mean(\n",
    "            w_batch * torch.nn.CrossEntropyLoss(reduction='none')(y_p_pred, y_p_batch.long()))\n",
    "        loss = v_loss + p_loss\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "\n",
    "        it_losses.append(loss.item())\n",
    "    it_loss = np.mean(it_losses)\n",
    "    losses.append(it_loss)\n",
    "\n",
    "    print(f'Iteration {it}: loss = {it_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(losses)\n",
    "plt.title('Average loss per iteration')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(vp_net.state_dict(), 'vp_net.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
